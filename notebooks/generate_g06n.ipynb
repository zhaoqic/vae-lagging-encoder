{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import math\n",
    "import importlib\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from tqdm import tqdm, trange\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "from data import SupervisedTextData\n",
    "from text_supervised import init_config\n",
    "from modules import SemisupervisedVAE\n",
    "from modules import LSTMEncoder, LSTMDecoder\n",
    "from logger import Logger\n",
    "\n",
    "\n",
    "class uniform_initializer(object):\n",
    "    def __init__(self, stdv):\n",
    "        self.stdv = stdv\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        nn.init.uniform_(tensor, -self.stdv, self.stdv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVED_MODELS = {\n",
    "    (783435, 0): 'models/g06n/g06n_aggressive1_kls0.10_warm10_0_0_783435.pt',\n",
    "    (101, 1): 'models/g06n/g06n_aggressive1_kls0.10_warm10_0_1_101.pt',\n",
    "    (202, 2): 'models/g06n/g06n_aggressive1_kls0.10_warm10_0_2_202.pt',\n",
    "    (303, 3): 'models/g06n/g06n_aggressive1_kls0.10_warm10_0_3_303.pt',\n",
    "}\n",
    "\n",
    "model_seed, task_id = 101, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = init_config(f'--dataset g06n --seed {model_seed} --taskid {task_id} '\n",
    "                   f'--decode_from {SAVED_MODELS[(model_seed,task_id)]}')\n",
    "args.device = torch.device(f\"cuda:{args.cudaid}\" if args.cuda else \"cpu\")\n",
    "\n",
    "print('>> Loading training data...')\n",
    "train_data = SupervisedTextData(fdoc=args.train_doc, fnum=args.train_num, flabel=args.train_label)\n",
    "train_texts = np.load('./datasets/g06n_data/g06n.doc.train.npy')\n",
    "#test_label = np.load('g06n.label.test.npy')\n",
    "#val_label = np.load('g06n.label.valid.npy')\n",
    "\n",
    "print('>> Loading model and weights...')\n",
    "model_init = uniform_initializer(0.01)\n",
    "emb_init = uniform_initializer(0.1)\n",
    "encoder = LSTMEncoder(args, len(train_data.vocab), model_init, emb_init)\n",
    "decoder = LSTMDecoder(args, train_data.vocab, model_init, emb_init)\n",
    "svae = SemisupervisedVAE(encoder, decoder, args).to(args.device)\n",
    "svae.load_state_dict(torch.load(args.decode_from, map_location=args.device))\n",
    "svae.eval()\n",
    "\n",
    "print('>> All is loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    def diff_words(row, baseline_col = 'recon_0'):\n",
    "        baseline_vocab = set(row[baseline_col].split())\n",
    "        return ({\n",
    "            i: ' '.join([word for word in row[i].split() if word not in baseline_vocab])\n",
    "            for i in row.index if i.startswith('recon')\n",
    "        })\n",
    "\n",
    "\n",
    "    # generate new documents and save them under `./generated/` folder\n",
    "    args.decoding_strategy = 'greedy'\n",
    "    seed = 0\n",
    "    random.seed(seed)\n",
    "\n",
    "    patent_idx = random.sample(range(len(train_data)), 1024)\n",
    "    batch_texts = train_texts[patent_idx]\n",
    "    batch_docs, batch_nums, batch_labels, _ = train_data[patent_idx]\n",
    "    batch_docs, _ = train_data.to_tensor(batch_docs, batch_first=True, device=args.device)\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        z, kl, mu, var = svae.encoder.encode(batch_docs, args.nsamples, return_var=True)\n",
    "        for lat_idx in trange(32):\n",
    "            df_results = pd.DataFrame(index=batch_labels)\n",
    "            df_results['origin'] = batch_texts\n",
    "            for i in (-50, -10, -5, -1, 0, 1, 5, 10, 50):\n",
    "                mask = torch.zeros_like(var)\n",
    "                mask[:, lat_idx] = i\n",
    "                #df_results[f'recon_{i}'] = [' '.join(d) for d in svae.decode(mu + mask * var, args.decoding_strategy)]\n",
    "                df_results[f'recon_{i}'] = [' '.join(d) for d in svae.decode(mu + mask, args.decoding_strategy)]\n",
    "                \n",
    "            filename = f'{args.dataset}_{args.seed}_seed{seed}_lat{lat_idx:02d}.csv'\n",
    "            df_results.to_csv(f'./generated/{filename}')\n",
    "            \n",
    "            # the reconstructed documnetare too messy, instead, we only look at the differences \n",
    "            df_results.apply(diff_words, axis=1, result_type='expand').to_csv(f'../difference/{filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    args.decoding_strategy = 'beam'\n",
    "    assert args.decoding_strategy in ('beam', 'greedy', 'sample')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        z = svae.sample_from_prior(100)\n",
    "        decoded_batch = svae.decode(z, args.decoding_strategy, K=5)\n",
    "\n",
    "    [' '.join(b) for b in decoded_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    batch_size = 2048\n",
    "    train_data_iter = train_data.data_iter(batch_size, 'cuda', batch_first=True, shuffle=False)\n",
    "\n",
    "    z_list = []\n",
    "    mu_list = []\n",
    "    nums_list = []\n",
    "    with torch.no_grad():\n",
    "        for docs, nums, sents_len in tqdm(train_data_iter, total=math.ceil(len(train_data)/batch_size)):\n",
    "            z, kl, mu = svae.encoder.encode(docs, args.nsamples, return_mu=True)\n",
    "            z_list.append(z.cpu().numpy())\n",
    "            mu_list.append(mu.cpu().numpy())\n",
    "            nums_list.append(nums)\n",
    "\n",
    "    z_array = np.concatenate(z_list).squeeze()\n",
    "    mu_array = np.concatenate(mu_list).squeeze()\n",
    "    nums_array = np.concatenate(nums_list).squeeze()\n",
    "\n",
    "    i = 0\n",
    "    fig = plt.figure(dpi=120)\n",
    "    ax = fig.gca()\n",
    "    ax.scatter(nums_array[:1000, i], mu_array[:1000,i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
